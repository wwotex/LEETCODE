instead of typical C++ syntax use Python functions: 
    for i, el in enumerate(list):
    for el1, el2 in zip(l1, l2):

instead of left and right prefix tables use total sum and a dynamically changing left prefix:
    S = sum(nums)
    leftsum = 0
    for i, el in enumerate(nums):
        if leftsum == (S - el - leftsum):
            return i
        leftsum += el

python dictionary to check if something exists AND if it is equal something use .get function:
    instead of:
        if el not in D or D[el] != x:
    use:
        if D.get(el) != x:

reversing linked lists - quite complicated to get it right - important intuition behind iterative approach -> 
first at each step you save the next node and then you redirect the "arrow" from current to previous node and then
you rename previous to current and current to next
    def reverseList(self, head: Optional[ListNode]) -> Optional[ListNode]:
        curr = head
        prev = None
        while curr is not None:
            next = curr.next
            curr.next = prev
            prev = curr
            curr = next
        return prev

prefix sum with dictionary method 
keeping the prefix sum and saving them in the dictionary to find all paths that sum to target

for algorithms like BFS from multiple starting points with keeping track of the timesteps 
instead of using two queues (one as a buffer) use a delimiter element to add timesteps

instead of 
    cell = Q.pop()
use
    (x, y) = Q.pop()

when using nested functions use the NONLOCAL keyword for accessing nonlocal variables

minStack -> use two stacks the other one for keeping track of the minimum value at each point

fajny szybki zapis: 
prev, curr = curr, max( ..... )

sliding window: 
zamiast while loop tak jak przy two pointers lepiej for loop i while loop w środku w którym upewniasz się że warunek jest zachowany i przesuwasz
wskaźnik w whileu a prawy w forze 
left, result, prod = 0, 0, 1
for right, el in enumerate(nums):
    prod *= el
    while prod >= k:
        prod /= nums[left]
        left += 1
    result += right - left + 1

DODATKOWO:
number of subarrays in an array is n(n+1)/2 ponieważjesli się nad tym zastanowisz to zaczynając od jednego elementu każdy kolejny dodany element 
dodaje kolejną liczbę całkowitą ilości możliwych tablic
1
O 
  2
  O
O O
    3
    O
  O O 
O O O 
etc 
więc równie dobrze w metodzie sliding window można dodawać kolejne liczby rzeczywiste czyli jeśli prawy wskaźnik przesuwasz o jeden to dodajesz
do wyniku 
right - left + 1
czyli długość rozpatrywanej tabeli (od lewego do prawego wskaźnika)

PRODUCT in an ARRAY:
smart point is that log(product) = sum(logarithms) -> good if the products are too big 

Kadane’s Algorithm -> subarray with max sum -> oh wow... 
for i in range(1, len(nums)):
    if nums[i-1] > 0:
        nums[i] += nums[i-1]
return max(nums)
dynamic programming -> dla każdego elementu zapisujesz najlepszy wynik kończący się w tym elemencie -> DP rozwiązania zawsze się opierają na takiej
                        logice że na każdym etapie zapisujesz najlepszy wynik do tej pory ... albo najlepszy zaczynający się /kończący w tym miejscu
                        albo najlepszy dla tej ilości elementów 
i jeśli najlepszy wynik dla tablic kończących się o jedno pole przed tym co teraz rozpatrujemy to na pewno nie opłaca się łączyć tego co mamy teraz
z tym co było bo tylko zmniejszamy wynik
FOR CYCLIC ARRAYS
important note is that the max "wrapping" sum is (total sum - min sum)
[ PART OF MAX SUM SUBARRAY ][ MIN SUBARRAY ][ PART OF MAX SUM SUBARRAY ]


in python you can actually keep passing the same array multiple times and it does not get copied only a reference to it is there
good for post-order iterative DFS tree traversal

DP -> selling stocks taught me to take DP problems in the form of FSM (finite state machines)

LEARN SEGMENT TREES

maximal square question -> very interesting way of looking at some problems that once you solve
                            for a smaller square you also know that this helps you with figuring out
                            bigger squares and that a big square has to contain small squares